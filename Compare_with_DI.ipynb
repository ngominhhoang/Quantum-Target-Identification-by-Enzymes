{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/dwavesystems/dwave-ocean-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ising_extract_from_fasthare(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    new_ising = {}\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        #print(line)\n",
    "        if line == '':\n",
    "            break\n",
    "        arr = line[0:-1].split(' ')\n",
    "        if len(arr) == 3:\n",
    "            new_ising[(int(arr[0]), int(arr[1]))] = -float(arr[2])\n",
    "    return new_ising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(state, target):\n",
    "  check = {}\n",
    "  for comp in G_metabolic.nodes:\n",
    "    check[comp] = True\n",
    "  queue = []\n",
    "  for i in range(0, len(list_enzymes)):\n",
    "    if state[i] == 1:\n",
    "      queue.append(list_enzymes[i])\n",
    "      check[list_enzymes[i]] = False\n",
    "  \n",
    "  while queue:\n",
    "    head = queue.pop(0)\n",
    "    list_successor = [i for i in G_metabolic.neighbors(head)]\n",
    "    for comp in list_successor:\n",
    "      if check[comp]:\n",
    "        if comp in list_compounds:\n",
    "          list_predecessor = [i for i in G_metabolic.predecessors(comp)]\n",
    "          double_check = True\n",
    "          for comp_pre in list_predecessor:\n",
    "            if check[comp_pre]:\n",
    "              double_check = False\n",
    "              break\n",
    "          if double_check:\n",
    "            check[comp] = False\n",
    "            queue.append(comp)\n",
    "        else:\n",
    "          check[comp] = False\n",
    "          queue.append(comp)\n",
    "  damage = 0\n",
    "  removal = 0\n",
    "  for comp in list_compounds:\n",
    "    if comp in target:\n",
    "      removal = removal + (check[comp] == False)\n",
    "      #if check[comp]:\n",
    "      #  print(comp)\n",
    "    else:\n",
    "      #if not check[comp]:\n",
    "      #  print(comp)\n",
    "      damage = damage + (check[comp] == False)\n",
    "      \n",
    "  return damage, removal == len(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b5230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def di_initialize(list_enzymes, list_reactions, list_compounds, target):\n",
    "  score_enzymes = {}\n",
    "  state = [0]*len(list_enzymes)\n",
    "  for i in range(0, len(list_enzymes)):\n",
    "    state[i] = 1\n",
    "    damage, res = bfs(state, target)\n",
    "    state[i] = 0\n",
    "    score_enzymes[list_enzymes[i]] = damage\n",
    "\n",
    "  score_reactions = {}\n",
    "  saved_reactions = {}\n",
    "  for i in range(0, len(list_reactions)):\n",
    "    damage = 100000000\n",
    "    saved = []\n",
    "    list_predecessor = [i for i in G_metabolic.predecessors(list_reactions[i])]\n",
    "    for comp in list_predecessor:\n",
    "      if comp in list_enzymes:\n",
    "        if score_enzymes[comp] < damage:\n",
    "          damage = score_enzymes[comp]\n",
    "          saved = [comp]\n",
    "    score_reactions[list_reactions[i]] = damage\n",
    "    saved_reactions[list_reactions[i]] = saved\n",
    "\n",
    "  score_compounds = {}\n",
    "  saved_compounds = {}\n",
    "  for i in range(0, len(list_compounds)):\n",
    "    damage = 100000000\n",
    "    saved = []\n",
    "    list_predecessor = [i for i in G_metabolic.predecessors(list_compounds[i])]\n",
    "    for comp in list_predecessor:\n",
    "      saved = list(set(saved+saved_reactions[comp]))\n",
    "    state = [0]*len(list_enzymes)\n",
    "    for comp in saved:\n",
    "      state[list_enzymes.index(comp)] = 1\n",
    "    damage, res = bfs(state, target)\n",
    "    if len(saved) != 0:\n",
    "      score_compounds[list_compounds[i]] = damage\n",
    "      saved_compounds[list_compounds[i]] = saved\n",
    "    else:\n",
    "      score_compounds[list_compounds[i]] = 100000000\n",
    "      saved_compounds[list_compounds[i]] = saved\n",
    "  \n",
    "  return score_enzymes, score_reactions, saved_reactions, score_compounds, saved_compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def di_main(list_enzymes, list_reactions, list_compounds, score_enzymes, score_reactions, saved_reactions, score_compounds, saved_compounds, target, iter_limit):\n",
    "  iter = 0\n",
    "  while iter < iter_limit:\n",
    "    new_score_reactions = score_reactions.copy()\n",
    "    new_saved_reactions = saved_reactions.copy()\n",
    "    for i in range(0, len(list_reactions)):\n",
    "      list_predecessor = [i for i in G_metabolic.predecessors(list_reactions[i])]\n",
    "      for comp in list_predecessor:\n",
    "        if comp in list_compounds:\n",
    "          if score_compounds[comp] < new_score_reactions[list_reactions[i]]:\n",
    "            new_score_reactions[list_reactions[i]] = score_compounds[comp]\n",
    "            new_saved_reactions[list_reactions[i]] = saved_compounds[comp]\n",
    "\n",
    "    new_score_compounds = score_compounds.copy()\n",
    "    new_saved_compounds = saved_compounds.copy()\n",
    "    for i in range(0, len(list_compounds)):\n",
    "      saved = []\n",
    "      list_predecessor = [i for i in G_metabolic.predecessors(list_compounds[i])]\n",
    "      for comp in list_predecessor:\n",
    "        saved = list(set(saved+new_saved_reactions[comp]))\n",
    "      \n",
    "      state = [0]*len(list_enzymes)\n",
    "      for comp in saved:\n",
    "        state[list_enzymes.index(comp)] = 1\n",
    "      damage, res = bfs(state, target)\n",
    "\n",
    "      if damage < new_score_compounds[list_compounds[i]]:\n",
    "        new_score_compounds[list_compounds[i]] = damage\n",
    "        new_saved_compounds[list_compounds[i]] = saved\n",
    "    \n",
    "    check_stop = True\n",
    "    for comp in list_reactions:\n",
    "      if new_score_reactions[comp] != score_reactions[comp]:\n",
    "        check_stop = False\n",
    "        break\n",
    "\n",
    "    for comp in list_compounds:\n",
    "      if new_score_compounds[comp] != score_compounds[comp]:\n",
    "        check_stop = False\n",
    "        break\n",
    "    \n",
    "    if check_stop:\n",
    "      break\n",
    "    else:\n",
    "      score_reactions = new_score_reactions.copy()\n",
    "      saved_reactions = new_saved_reactions.copy()\n",
    "      score_compounds = new_score_compounds.copy()\n",
    "      saved_compounds = new_saved_compounds.copy()\n",
    "      iter = iter + 1\n",
    "  return score_enzymes, score_reactions, saved_reactions, score_compounds, saved_compounds, iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09cf942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def di_extract_results(list_enzymes, saved_compounds, target):\n",
    "  removed_enzymes = []\n",
    "  for comp in target:\n",
    "    removed_enzymes = removed_enzymes + saved_compounds[comp]\n",
    "  removed_enzymes = list(set(removed_enzymes))\n",
    "\n",
    "  bits = [0]*len(list_enzymes)\n",
    "  for i in range(0, len(list_enzymes)):\n",
    "    if list_enzymes[i] in removed_enzymes:\n",
    "      bits[i] = 1\n",
    "  damage, res = bfs(bits, target)\n",
    "  return damage, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aeeb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def di_generate_target(sz, list_compounds):\n",
    "  if sz >= len(list_compounds):\n",
    "    return []\n",
    "\n",
    "  return random.sample(list_compounds, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de771c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigger(k1, k2):\n",
    "  if type(k1) is type(k2):\n",
    "    return k1 > k2\n",
    "  else:\n",
    "    if type(k1) is int:\n",
    "      return False\n",
    "    else:\n",
    "      return True\n",
    "\n",
    "def extract_quadratic_func(input_comp):\n",
    "  temp_comp = {}\n",
    "  keys = input_comp.keys()\n",
    "  for k in keys:\n",
    "    if type(k) is not int:\n",
    "      temp_comp[k] = input_comp[k]*input_comp[k]\n",
    "  for k1 in keys:\n",
    "    for k2 in keys:\n",
    "      if (k1 != k2) and (bigger(k1, k2)):\n",
    "        if type(k1) is int:\n",
    "          if type(k2) is not int:\n",
    "            temp_comp[k2] = temp_comp[k2] + 2*input_comp[k1]*input_comp[k2]\n",
    "        else:\n",
    "          if type(k2) is int:\n",
    "            temp_comp[k1] = temp_comp[k1] + 2*input_comp[k2]*input_comp[k1]\n",
    "          else:\n",
    "            if (k1, k2) not in temp_comp.keys():\n",
    "              temp_comp[(k1, k2)] = 2*input_comp[k1]*input_comp[k2]\n",
    "            else:\n",
    "               temp_comp[(k1, k2)] = temp_comp[(k1, k2)] + 2*input_comp[k1]*input_comp[k2]\n",
    "  return temp_comp\n",
    "\n",
    "def combine_comp(qubo_comp, temp_comp, ins):\n",
    "  keys = temp_comp.keys()\n",
    "  for k in keys:\n",
    "    if k not in qubo_comp:\n",
    "      qubo_comp[k] = temp_comp[k] * ins\n",
    "    else:\n",
    "      qubo_comp[k] = qubo_comp[k] + temp_comp[k] * ins\n",
    "  return qubo_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubo_initialize(list_enzymes, list_reactions, list_compounds, target):\n",
    "  C = target\n",
    "  qubo_comp = {}\n",
    "  A1 = 1\n",
    "  A2 = 300\n",
    "  A3 = 250\n",
    "  A4 = 250\n",
    "  coefficient = 0\n",
    "  for comp in list_compounds:\n",
    "    if comp not in C:\n",
    "      qubo_comp[comp] = A1\n",
    "    else:\n",
    "      print\n",
    "      qubo_comp[comp] = -A2\n",
    "      coefficient = coefficient + A2\n",
    "\n",
    "  for comp_i in list_compounds:\n",
    "    list_predecessor = [i for i in G_metabolic.predecessors(comp_i)]\n",
    "\n",
    "    for comp_j in list_predecessor:\n",
    "      temp_comp = extract_quadratic_func({comp_i: 1, comp_j: -1})\n",
    "      qubo_comp = combine_comp(qubo_comp, temp_comp, A3)\n",
    "    \n",
    "    for comp_j in list_predecessor:\n",
    "      temp_comp = extract_quadratic_func({comp_i: 1, comp_j: -1, 1:1})\n",
    "      qubo_comp = combine_comp(qubo_comp, temp_comp, A3)\n",
    "      #coefficient = coefficient + A3\n",
    "    \n",
    "    input_comp = {comp_i: -1, 1:1}\n",
    "    for comp_j in list_predecessor:\n",
    "      input_comp[comp_j] = 1\n",
    "    \n",
    "    for i in range(0, len(list_predecessor) + 1):\n",
    "      input_comp['W_'+str(comp_i)+'_'+str(i)] = -i\n",
    "    \n",
    "    temp_comp = extract_quadratic_func(input_comp)\n",
    "    qubo_comp = combine_comp(qubo_comp, temp_comp, A3)\n",
    "    coefficient = coefficient + A3\n",
    "\n",
    "    input_comp = {1:1}\n",
    "    for i in range(0, len(list_predecessor) + 1):\n",
    "      input_comp['W_'+str(comp_i)+'_'+str(i)] = -1\n",
    "    \n",
    "    temp_comp = extract_quadratic_func(input_comp)\n",
    "    qubo_comp = combine_comp(qubo_comp, temp_comp, A3)\n",
    "    coefficient = coefficient + A3\n",
    "\n",
    "  for comp_i in list_reactions:\n",
    "    list_predecessor = [i for i in G_metabolic.predecessors(comp_i)]\n",
    "    removal_list = []\n",
    "    if is_revertable[comp_i]:\n",
    "      for comp_j in list_predecessor:\n",
    "        if comp_j in list_compounds:\n",
    "          removal_list.append(comp_j)\n",
    "    for comp_j in removal_list:\n",
    "      list_predecessor.remove(comp_j)\n",
    "    for comp_j in list_predecessor:\n",
    "      temp_comp = extract_quadratic_func({comp_i: 1, comp_j: -1})\n",
    "      qubo_comp = combine_comp(qubo_comp, temp_comp, A4)\n",
    "    \n",
    "    for comp_j in list_predecessor:\n",
    "      temp_comp = extract_quadratic_func({comp_i: 1, comp_j: -1, 1:-1})\n",
    "      qubo_comp = combine_comp(qubo_comp, temp_comp, A4)\n",
    "      #print(comp_i, temp_comp)\n",
    "      #coefficient = coefficient - A4\n",
    "    \n",
    "    input_comp = {comp_i: 1}\n",
    "    for comp_j in list_predecessor:\n",
    "      input_comp[comp_j] = -1\n",
    "    \n",
    "    for i in range(0, len(list_predecessor) + 1):\n",
    "      input_comp['T_'+str(comp_i)+'_'+str(i)] = i\n",
    "    \n",
    "    temp_comp = extract_quadratic_func(input_comp)\n",
    "    qubo_comp = combine_comp(qubo_comp, temp_comp, A4)\n",
    "\n",
    "    input_comp = {1:1}\n",
    "    for i in range(0, len(list_predecessor) + 1):\n",
    "      input_comp['T_'+str(comp_i)+'_'+str(i)] = -1\n",
    "    \n",
    "    temp_comp = extract_quadratic_func(input_comp)\n",
    "    qubo_comp = combine_comp(qubo_comp, temp_comp, A4)\n",
    "    coefficient = coefficient + A4\n",
    "  return qubo_comp, coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1be8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dimod import BinaryQuadraticModel\n",
    "from dwave.system import LeapHybridSampler\n",
    "\n",
    "def qubo_splitting(qubo_comp):\n",
    "  linear_comp = {}\n",
    "  quadratic_comp = {}\n",
    "  for k in qubo_comp.keys():\n",
    "    if type(k) is str:\n",
    "      linear_comp[k] = qubo_comp[k]\n",
    "    else:\n",
    "      quadratic_comp[k] = qubo_comp[k]\n",
    "  return linear_comp, quadratic_comp\n",
    "\n",
    "def qubo_main(linear_comp, quadratic_comp, coefficient, target, time_limit_):\n",
    "  bqm = BinaryQuadraticModel(linear_comp,\n",
    "                           quadratic_comp,\n",
    "                           coefficient,\n",
    "                           'BINARY')\n",
    "  sampler = LeapHybridSampler()\n",
    "  sampleset = sampler.sample(bqm,time_limit=time_limit_)\n",
    "  print(sampleset.lowest(atol=.5))\n",
    "\n",
    "  removed_enzymes_2 = []\n",
    "  for comp in list_enzymes:\n",
    "    if sampleset.first.sample[comp] == 1:\n",
    "      removed_enzymes_2.append(comp)\n",
    "  \n",
    "  bits_2 = [0]*len(list_enzymes)\n",
    "  for i in range(0, len(list_enzymes)):\n",
    "    if list_enzymes[i] in removed_enzymes_2:\n",
    "      bits_2[i] = 1\n",
    "  \n",
    "  damage, res = bfs(bits_2, target)\n",
    "  return damage, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self generate targets\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.shortest_paths.unweighted import predecessor\n",
    "import dimod\n",
    "import time\n",
    "from subprocess import call\n",
    "\n",
    "pathway_list = ['Purine', 'Carbon metabolism', 'Nucleotide metabolism', 'Biosynthesis of amino acids']\n",
    "species_name = 'hsa'\n",
    "data_type = 'large'\n",
    "time_limit = 1200\n",
    "\n",
    "test_iterations = 2\n",
    "test_step = 5\n",
    "iter_limit = 20\n",
    "    \n",
    "for pathway_name in pathway_list:\n",
    "    list_enzymes = []\n",
    "    list_reactions = []\n",
    "    list_compounds = []\n",
    "    G_metabolic = nx.DiGraph()\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    mode = 0\n",
    "    with open('large_data/'+species_name+'_filtering/'+pathway_name+'.input') as f:\n",
    "        while mode <= 3:\n",
    "            if mode < 3:\n",
    "                num_nodes = int(f.readline())\n",
    "                #print(num_nodes)\n",
    "                for i in range(0, num_nodes):\n",
    "                    element = f.readline()\n",
    "                    #print(element)\n",
    "                    nodes.append(element[0:-1])\n",
    "                    if mode == 0:\n",
    "                        list_enzymes.append(element[0:-1])\n",
    "                    elif mode == 1:\n",
    "                        list_reactions.append(element[0:-1])\n",
    "                    else:\n",
    "                        list_compounds.append(element[0:-1])\n",
    "                mode = mode + 1\n",
    "            else:\n",
    "                num_edges = int(f.readline())\n",
    "                for i in range(0, num_edges):\n",
    "                    line = f.readline()\n",
    "                    element = line[0:-1].split(' ')\n",
    "                    edges.append(element)\n",
    "                mode = mode + 1\n",
    "    G_metabolic.add_edges_from(edges)\n",
    " \n",
    "    list_removal = []\n",
    "    for comp in G_metabolic.nodes:\n",
    "        list_predecessor = [i for i in G_metabolic.predecessors(comp)]\n",
    "        if comp in list_compounds and len(list_predecessor) == 0:\n",
    "            list_removal.append(comp)\n",
    "            list_compounds.remove(comp)\n",
    "    G_metabolic.remove_nodes_from(list_removal)\n",
    "\n",
    "    is_revertable = {}\n",
    "    for comp in list_reactions:\n",
    "        list_predecessor = [i for i in G_metabolic.predecessors(comp)]\n",
    "        list_successor = [i for i in G_metabolic.neighbors(comp)]\n",
    "        check = False\n",
    "        for comp_2 in list_predecessor:\n",
    "            if comp_2 in list_successor:\n",
    "                check = True\n",
    "                break\n",
    "        is_revertable[comp] = check\n",
    "    \n",
    "    sz = 1\n",
    "    testcase = []\n",
    "    while sz < len(list_compounds):\n",
    "        for it in range(0, test_iterations):\n",
    "            record = {}\n",
    "            target = di_generate_target(sz, list_compounds)\n",
    "            if len(target) == 0:\n",
    "                break\n",
    "            time_start = time.time()\n",
    "            score_enzymes, score_reactions, saved_reactions, score_compounds, saved_compounds = di_initialize(list_enzymes, list_reactions, list_compounds, target)\n",
    "\n",
    "            score_enzymes, score_reactions, saved_reactions, score_compounds, saved_compounds, iter = di_main(list_enzymes, list_reactions, list_compounds, score_enzymes, score_reactions, saved_reactions, score_compounds, saved_compounds, target, iter_limit)\n",
    "\n",
    "            damage, check = di_extract_results(list_enzymes, saved_compounds, target)\n",
    "            time_end = time.time()\n",
    "\n",
    "            record['Target_size'] = sz\n",
    "            record['Target'] = target\n",
    "            record['DI_damage'] = damage\n",
    "            record['DI_running_time'] = time_end - time_start\n",
    "            \n",
    "            \n",
    "            testcase.append(record)\n",
    "        sz = sz + test_step\n",
    "    \n",
    "    for record in testcase:\n",
    "        target = record['Target']\n",
    "        qubo_comp, coefficient = qubo_initialize(list_enzymes, list_reactions, list_compounds, target)\n",
    "\n",
    "        linear_comp, new_qubo = qubo_splitting(qubo_comp)\n",
    "        bqm = BinaryQuadraticModel(linear_comp,\n",
    "                                   new_qubo,\n",
    "                                   coefficient,\n",
    "                                   'BINARY')\n",
    "\n",
    "        ising_model = bqm.to_ising()\n",
    "        \n",
    "        total_nodes = 0\n",
    "        dict_nodes = {}\n",
    "        dict_edges = {}\n",
    "\n",
    "        linear_keys = ising_model[0].keys()\n",
    "        for k in linear_keys:\n",
    "            dict_nodes[k] = total_nodes\n",
    "            total_nodes = total_nodes + 1\n",
    "\n",
    "        quadratic_keys = ising_model[1].keys()\n",
    "        for k in quadratic_keys:\n",
    "            if ising_model[1][k] != 0:\n",
    "                node_1 = k[0]\n",
    "                node_2 = k[1]\n",
    "                dict_edges[(dict_nodes[node_1], dict_nodes[node_2])] = ising_model[1][k]\n",
    "\n",
    "\n",
    "        f = open(\"large_data/\"+species_name+\"_label_fasthare/\"+pathway_name+\".txt\", \"w\")\n",
    "\n",
    "        nd_keys = dict_nodes.keys()\n",
    "        ed_keys = dict_edges.keys()\n",
    "\n",
    "        countt = 0\n",
    "        for k in nd_keys:\n",
    "            if ising_model[0][k] != 0:\n",
    "                countt = countt + 1\n",
    "\n",
    "        f.write(str(len(nd_keys)+1)+' '+str(len(ed_keys)+countt)+'\\n')\n",
    "        for k in ed_keys:\n",
    "            node_1 = k[0]\n",
    "            node_2 = k[1]\n",
    "            weight = dict_edges[k]\n",
    "            #print(str(node_1)+' '+str(node_2)+' '+str(weight)+'\\n')\n",
    "            f.write(str(node_1)+' '+str(node_2)+' '+str(weight)+'\\n')\n",
    "\n",
    "        for k in nd_keys:\n",
    "            node_1 = dict_nodes[k]\n",
    "            node_2 = len(nd_keys)\n",
    "            weight = ising_model[0][k]\n",
    "            if weight == 0:\n",
    "                continue\n",
    "            f.write(str(node_1)+' '+str(node_2)+' '+str(weight)+'\\n')\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        command = ['python3','FastHare/parse.py','large_data/'+species_name+'_label_fasthare/'+pathway_name]\n",
    "        call(command)\n",
    "        command = ['./FastHare/fasthare','large_data/'+species_name+'_label_fasthare/'+pathway_name+'.net', 'large_data/'+species_name+'_label_fasthare/'+'output', '2', '0']\n",
    "        call(command)\n",
    "\n",
    "        filename = 'large_data/'+species_name+'_label_fasthare/'+'output_compress'\n",
    "        new_quadratic = ising_extract_from_fasthare(filename)\n",
    "        linear_comp = {}\n",
    "        #break\n",
    "        new_bqm = dimod.BinaryQuadraticModel.from_ising({}, new_quadratic, offset = ising_model[2])\n",
    "        #new_bqm = dimod.BinaryQuadraticModel.from_ising(ising_model[0], ising_model[1], offset = ising_model[2])\n",
    "\n",
    "        start = time.time()\n",
    "        sampler = LeapHybridSampler()\n",
    "        sampleset = sampler.sample(new_bqm,time_limit=time_limit)\n",
    "        end = time.time()\n",
    "        print(sampleset.lowest(atol=.5))\n",
    "        end = time.time()\n",
    "        \n",
    "        filename = 'large_data/'+species_name+'_label_fasthare/'+pathway_name+'.net'\n",
    "        new_quadratic = ising_extract_from_fasthare(filename)\n",
    "        linear_comp = {}\n",
    "        old_bqm = dimod.BinaryQuadraticModel.from_ising({}, new_quadratic, offset = ising_model[2])\n",
    "        \n",
    "        samples = {}\n",
    "        for sample in sampleset.samples():   \n",
    "            samples = sample\n",
    "\n",
    "        filename = 'large_data/'+species_name+'_label_fasthare/'+'output_flip'\n",
    "        state_ = {}\n",
    "        curr_idx = 0\n",
    "        f = open(filename, \"r\")\n",
    "        new_ising = {}\n",
    "        line = f.readline()\n",
    "        arr = line[0:-2].split(' ')\n",
    "        new_n = int(arr[0])\n",
    "        old_n = int(arr[1])\n",
    "\n",
    "        line = f.readline()\n",
    "        check_flip = line[0:-2].split(' ')\n",
    "        for i in range(0, new_n):\n",
    "            line = f.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "            #print(line)\n",
    "            arr = line[0:-2].split(' ')\n",
    "            for i in range(1, len(arr)):\n",
    "                node = int(arr[i])\n",
    "                if check_flip[node] == '1':\n",
    "                    #print(node)\n",
    "                    state_[node] = - samples[curr_idx]\n",
    "                else:\n",
    "                    state_[node] = samples[curr_idx]\n",
    "            curr_idx = curr_idx + 1\n",
    "        \n",
    "        f = open(\"large_output/\"+species_name+\"/\"+pathway_name+\".out\", \"a\")\n",
    "        f.write('Target_size\\n')\n",
    "        f.write(str(record['Target_size'])+'\\n')\n",
    "        f.write('Target\\n')\n",
    "        for enzy in record['Target']:\n",
    "            f.write(enzy+'\\n')\n",
    "        f.write('DI_damage\\n')\n",
    "        f.write(str(record['DI_damage'])+'\\n')\n",
    "        f.write('DI_running_time\\n')\n",
    "        f.write(str(record['DI_running_time'])+'\\n')\n",
    "        f.write('QC_damage\\n')\n",
    "        f.write(str(old_bqm.energy(state_)) + '\\n')\n",
    "        f.write('QC_QPU_access_time\\n')\n",
    "        f.write(str(sampleset.info['qpu_access_time']/1000000)+'\\n')\n",
    "        f.write('QC_running_time\\n')\n",
    "        f.write(str(sampleset.info['run_time']/1000000)+'\\n')\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
